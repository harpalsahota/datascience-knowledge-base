{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Patterns\n",
    "\n",
    "## Stochastic Gradient Descent\n",
    "- On large datasets stochastic gradient descent (SGD) is applied to mini-batches\n",
    "- This is called stochastic SGD and extensions of SGD e.g. Adam, Adamgrad etc... are the de facto optimiser used in modern-day machine learning frameworks\n",
    "\n",
    "- SGD requires training to take place iteratively on small batches therefore training happens in a loop\n",
    "- SGD finds a minimum, but not a closed-form solution, and so we have to detect whether the model convergence has happened\n",
    "- As a result, the error (called the loss) on the training dataset has to be monitored.\n",
    "- Overfitting can happen if the model complexity is higher than can be affored by the size and coverage of the dataset\n",
    "- It is difficult to know if the compexity is too high until we actually train the model on the dataset\n",
    "- Therefore, evaluation needs to be done within the training loop and error metrics on a witheld split of the training data (validation set).\n",
    "- Because training and validation datasets have been used i the training loop it is necessary to withhold yet another split of the training dataset called the test set.\n",
    "- Metrics are reported on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern 11: Useful Overfitting\n",
    "\n",
    "- Want to intentionally overfit on the training dataset\n",
    "- Perform training without regularisation, dropout, validation dataset or early stopping\n",
    "\n",
    "### Problem\n",
    "\n",
    "- Goal of a ML model is to generalise well to make good predictions on unseen data.\n",
    "- If the model overfits then the ability to generalise suffers and so do future predictions\n",
    "\n",
    "- For example, imagine we have system to model the physical enviroment\n",
    "- The model carries out iterative, numerical calculations to calculate the precise state of the system\n",
    "- Suppose all observations have a finite number of possibilites e.g. temperature is limited to 60 - 80 degrees celcius in increments of 0.01.\n",
    "- We can then create a training dataset for the ML system consisting of the complete input space and calculate lavels using the physical model\n",
    "- Splitting the training dataset would be counterproductive because we would then be expecting the model to learn parts of the input space it will not have seen in the training dataset.\n",
    "\n",
    "### Solutions\n",
    "\n",
    "- In the above scenario, there is no \"unseen\" data that needs to be generalised to, since all possible inputs have been tabulated\n",
    "- If all possible inputs to a model can be tabulated there is no such thing as overfitting\n",
    "\n",
    "- Typically, overfitting of the training dataset in this way causes the model to give misguided predictions on new, unseen datapoints\n",
    "- The difference here is that we know in advance there won't be unseen data\n",
    "\n",
    "### Why it Works\n",
    "\n",
    "- If all possible inputs can be tabulated, then an overfit model will make the same predictions as the \"true\" model if all possible inputs are trained for, so overfitting is not a concern\n",
    "\n",
    "- Overfitting is useful when:\n",
    "    - There is no noise, so the labels are accurate for all instances\n",
    "    - You have the complete dataset as your disposal (you have all the examples there are). In this case, overfitting becomes interpolating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Pattern 12: Checkpoints\n",
    "\n",
    "- With checkpoints we store the full state of the model periodically so that we have partially trained models available\n",
    "- These models can serve as the final model in the case of the final model or as a starting point for continued training\n",
    "\n",
    "### Problem\n",
    "\n",
    "- More complex model, more data is needed to train effectively\n",
    "- More complex models tend to have more tunable parameters\n",
    "- As model size increases the longer it takes to fit on one batch of data \n",
    "- As data increases the number of batches increases\n",
    "- In terms of computational complexity this is a double whammy\n",
    "\n",
    "- When training for a long time the chances of machine failure increases.\n",
    "- If there is a problem we would like to resume from an intermediate point\n",
    "\n",
    "### Solution\n",
    "\n",
    "- At the end of every epoch save the model state\n",
    "- If a machine failure occures we can resume from the saved state and restart\n",
    "- Make sure the full model state is saved not the just the model\n",
    "- Once training is complete and exported it is usually only the information required to make a prediciton is saved\n",
    "\n",
    "- Good to save information about the training loop as well e.g.\n",
    "    - Learning rate in a learning rate scheduler\n",
    "    - Batch number\n",
    "- Saving a full model state so that is can be resumed is called checkpointing\n",
    "- Model states changes with every batch but there is much overhead to save at every batch so do it at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example to save model state in pytorch\n",
    "\n",
    "```\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_stat_dict': model.state_dict(),\n",
    "    'optimiser_state_dict': optimiser.state_dict(),\n",
    "    'loss': loss,\n",
    "    ...\n",
    "}, PATH)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why it Works\n",
    "\n",
    "- Most ML frameworks can result from a saved checkpoint\n",
    "- Checkpoints are designed for mainly for resilience, their availability however opens other use cases\n",
    "- Partially trained models are usually more generalisable that models created later iterations \n",
    "    - [See here](https://playground.tensorflow.org/)\n",
    "    \n",
    "### Trade-Offs and Alternatives\n",
    "\n",
    "- Saving checkpoints allows us to implement early stopping and fine-tuning capabilities\n",
    "\n",
    "#### Early Stopping\n",
    "\n",
    "- Typically, the longer you train the lower your training loss\n",
    "- At a certain point the loss on the validation set may stoping decreasing\n",
    "- If you being to overfit the error on the validation set may increase\n",
    "- Handy to look at the validation error at the end of every epoch and stop the training process when the validation error is more than that of the previous epoch\n",
    "\n",
    "#### Checkpoint Selection\n",
    "\n",
    "- It's not uncommon for the validation error to decrease, increase slightly then decrease again, therefore early stopping of the validation loss increases may not be optimum\n",
    "- This is because the training initally focuses on common cases, then begings to look at rarer cases [Paper](https://arxiv.org/abs/1912.02292)\n",
    "- Therefore training should continue for a while longer\n",
    "\n",
    "#### Regularisation\n",
    "\n",
    "- Instead of early stopping or checkpoint selection, it can be helpful to add L2 regularisation to your model so that the validation error does not increase.\n",
    "- Instead, both the training loss and the validation error plateau. We term such a training loop where both training and validation plateau a well-behaved training loop\n",
    "\n",
    "- Regularisation might be better than early stopping is that regularisation allows you to use the entire dataset to change the weights of the model\n",
    "- With early stopping you have to decide where to stop on the validation set so some data is wasted in this set\n",
    "\n",
    "#### Two-Splits\n",
    "\n",
    "- Recommended to split data into two parts: a training set and evaluation set\n",
    "- Evaluation set plays the part of the test dataset during training\n",
    "\n",
    "- A larger training dataset allows for a more complex model and the more accurate the model can get\n",
    "- Using regularisation rather than early stopping or checkpoint selection allows you to use a larget training dataset\n",
    "- During the experimentation phase e.g. hyperparm and model architecture exploring, early stopping should be turned off\n",
    "- This ensures the model has enough capacity to learn the predictive patterns.\n",
    "\n",
    "- When training a model for prod be prepped for continuous evaluation and model retraining\n",
    "\n",
    "#### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
