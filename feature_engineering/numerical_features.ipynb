{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    StandardScaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation\n",
    "\n",
    "This is the process of translating a range of values which are numerical into another range, typically $[-1, 1]$ or $[0, 1]$\n",
    "\n",
    "Say for example a numerical feature ranges from 250 – 1000. If the minimum of this feature (250) was subtracted from all the features and then divided by the difference between the min and max of the feature (1000 – 250 = 750) it would normalise the feature between 0 and 1. This can expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bar{x}^{(j)} = \\frac{x^{(j)} -  min^{(j)}}{max^{(j)} - min^{(j)}}\n",
    "\\end{equation}\n",
    "\n",
    "where $min^{(j)}$ and $max^{(j)}$ are the minimum and maximum of the feature ($j$) respectively.\n",
    "\n",
    "Normalising is important to help increase training speed although it is not strictly required. For example, if we are training a model on two features ranging from 0 - 1 and 0 - 10,000 then the derivative with respect to the larger feature will dominate the update. Generally speaking, it is good practise to ensure the features are in similar ranges when training a model.\n",
    "\n",
    "We can do this the `MinMaxScaler` in sklearn. Example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([5, 10, 6, 5, 8, 7, 8, 9, 9, 5, 10]).reshape(-1, 1)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [1. ],\n",
       "       [0.2],\n",
       "       [0. ],\n",
       "       [0.6],\n",
       "       [0.4],\n",
       "       [0.6],\n",
       "       [0.8],\n",
       "       [0.8],\n",
       "       [0. ],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has now been scaled between 0 and 1 where the initial range was from 5 - 10\n",
    "\n",
    "## Standardisation\n",
    "\n",
    "This method of scaling ensures the given feature when re-scaled have the properties of the standard normal distribution where $\\mu=0$ and $\\sigma=1$.\n",
    "- $\\mu$: Average value in the dataset\n",
    "- $\\sigma$: Standard deviation from the mean\n",
    "The calculation of standard scores (A.K.A z-score) can be formulated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{x}^{(j)} = \\frac{x^{(j)} -  \\mu^{(j)}}{\\sigma^{(j)}}\n",
    "\\end{equation}\n",
    "\n",
    "Should you noramlise or standardise a feature? There is no correct answer here, try both and see what works best on your dataset. If you are short on time, generally speaking:\n",
    "- Unsupervised methods benefit more from standardisation\n",
    "- If the feature is normally distributed standardisation is preferred\n",
    "- Features with extreme outliers standardisation will be  preferred as normalisation will compress normal values into a tight range\n",
    "- In other cases it should be okay to use either.\n",
    "\n",
    "Sklearn example of using standardisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform(data)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean column wise should be zero\n",
    "transformed.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate standard deviation column wise should be 1\n",
    "transformed.std(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
