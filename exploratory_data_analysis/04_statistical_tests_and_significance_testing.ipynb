{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Experiments and Significance Testing\n",
    "\n",
    "Design of experiments is a cornerstone of the practice of statistics, with\n",
    "applications in virtually all areas of research. The goal is to design an experiment\n",
    "in order to confirm or reject a hypothesis.\n",
    "\n",
    "This process starts with a hypothesis.\n",
    "An experiment is designed to test the hypothesis \n",
    "designed in such a way that, hopefully, will deliver conclusive results. The data\n",
    "is collected and analyzed, and then a conclusion is drawn. The term inference\n",
    "reflects the intention to apply the experiment results, which involve a limited set\n",
    "of data, to a larger process or population.\n",
    "\n",
    "Formulate Hypothesis &#8594; Design Experiment &#8594; Collect Data &#8594; Inference / Conclusions\n",
    "\n",
    "## A/B Testing\n",
    "\n",
    "An A/B test is an experiment with two groups to establish which of two\n",
    "treatments, products, procedures, or the like is superior. Often one of the two\n",
    "treatments is the standard existing treatment, or no treatment. If a standard (or\n",
    "no) treatment is used, it is called the control. A typical hypothesis is that\n",
    "treatment is better than control.\n",
    "\n",
    "- **Treatment**: Something (drug, price, web headline) to which a subject is exposed.\n",
    "- **Treatment group**: A group of subjects exposed to a specific treatment.\n",
    "- **Control group**: A group of subjects exposed to no (or standard) treatment.\n",
    "- **Randomization**: The process of randomly assigning subjects to treatments.\n",
    "- **Subjects**: The items (web visitors, patients, etc.) that are exposed to treatments.\n",
    "- **Test statistic**: The metric used to measure the effect of the treatment.\n",
    "\n",
    "A/B Test examples:\n",
    "- Testing two prices to determine which yields more net profit\n",
    "- If a new iteration of a model has a higher click-through rate compared to the current model\n",
    "\n",
    "A proper A/B test has subjects that can be assigned to one treatment or another.\n",
    "The subject might be a person, a plant seed, a web visitor; the key is that the\n",
    "subject is exposed to the treatment. Ideally, subjects are randomized (assigned\n",
    "randomly) to treatments. In this way, you know that any difference between the\n",
    "treatment groups is due to one of two things:\n",
    "- The effect of the different treatments\n",
    "- Luck of the draw in which subjects are assigned to which treatments (i.e., the random assignment may have resulted in the naturally better-performing subjects being concentrated in A or B)\n",
    "\n",
    "You also need to pay attention to the test statistic or metric you use to compare\n",
    "group A to group B. Perhaps the most common metric in data science is a binary\n",
    "variable: click or no-click, buy or don’t buy, fraud or no fraud, and so on. Those\n",
    "results would be summed up in a 2×2 table e.g.:\n",
    "\n",
    "| Outcome       | Model A | Model B |\n",
    "|---------------|---------|---------|\n",
    "| Conversion    | 450     | 350     |\n",
    "| No conversion | 53489   | 49278   |\n",
    "\n",
    "If the metric is a continuous variable (purchase amount, profit, etc.), or a count\n",
    "(e.g., days in hospital, pages visited) the result might be displayed differently. If\n",
    "one were interested not in conversion, but in revenue per page view, the results\n",
    "of the test in the table above could be mean revenue per page view along the top row\n",
    "and the standard deviation along the bottom.\n",
    "\n",
    "### Why Have a Control Group?\n",
    "\n",
    "Without a control group, there is no assurance that “other things are equal” and\n",
    "that any difference is really due to the treatment (or to chance). When you have a\n",
    "control group, it is subject to the same conditions (except for the treatment of\n",
    "interest) as the treatment group. If you simply make a comparison to “baseline”\n",
    "or prior experience, other factors, besides the treatment, might differ.\n",
    "\n",
    "The use of A/B testing in data science is typically in a web context. Treatments\n",
    "might be the design of a web page, the price of a product, the wording of a\n",
    "headline, or some other item. Some thought is required to preserve the principles\n",
    "of randomization. Typically the subject in the experiment is the web visitor, and\n",
    "the outcomes we are interested in measuring are clicks, purchases, visit duration,\n",
    "number of pages visited, whether a particular page is visited, and the like. In a\n",
    "standard A/B experiment, you need to decide on one metric ahead of time.\n",
    "Multiple behavior metrics might be collected and be of interest, but if the\n",
    "experiment is expected to lead to a decision between treatment A and treatment\n",
    "B, a single metric, or test statistic, needs to be established beforehand. **Selecting\n",
    "a test statistic after the experiment is conducted opens the door to researcher\n",
    "bias.**\n",
    "\n",
    "### Why Just A/B? Why Not C, D…?\n",
    "\n",
    "A/B tests are popular in the marketing and ecommerce worlds, but are far from\n",
    "the only type of statistical experiment. Additional treatments can be included.\n",
    "Subjects might have repeated measurements taken. Pharmaceutical trials where\n",
    "subjects are scarce, expensive, and acquired over time are sometimes designed\n",
    "with multiple opportunities to stop the experiment and reach a conclusion.\n",
    "\n",
    "## Hypothesis Tests\n",
    "\n",
    "Hypothesis tests, also called significance tests, are ubiquitous in the traditional\n",
    "statistical analysis of published research. **Their purpose is to help you learn\n",
    "whether random chance might be responsible for an observed effect.**\n",
    "\n",
    "- **Null hypothesis**: The hypothesis that chance is to blame.\n",
    "- **Alternative hypothesis**: Counterpoint to the null (what you hope to prove).\n",
    "- **One-way test**: Hypothesis test that counts chance results only in one direction.\n",
    "- **Two-way test**: Hypothesis test that counts chance results in two directions.\n",
    "\n",
    "An A/B test is typically constructed with a hypothesis in\n",
    "mind. For example, the hypothesis might be that price B produces higher profit.\n",
    "Why do we need a hypothesis? Why not just look at the outcome of the\n",
    "experiment and go with whichever treatment does better?\n",
    "\n",
    "The answer lies in the tendency of the human mind to underestimate the scope of\n",
    "natural random behavior. One manifestation of this is the failure to anticipate\n",
    "extreme events, or so-called \"black swans\".\n",
    "Another manifestation is the tendency to misinterpret random events as having\n",
    "patterns of some significance. Statistical hypothesis testing was invented as a\n",
    "way to protect researchers from being fooled by random chance.\n",
    "\n",
    "### The Null Hypothesis\n",
    "\n",
    "Hypothesis tests use the following logic: “Given the human tendency to react to\n",
    "unusual but random behavior and interpret it as something meaningful and real,\n",
    "in our experiments we will require proof that the difference between groups is\n",
    "more extreme than what chance might reasonably produce.” This involves a\n",
    "baseline assumption that the treatments are equivalent, and any difference\n",
    "between the groups is due to chance. This baseline assumption is termed the null\n",
    "hypothesis. Our hope is then that we can, in fact, prove the null hypothesis\n",
    "wrong, and show that the outcomes for groups A and B are more different than\n",
    "what chance might produce.\n",
    "\n",
    "One way to do this is via a resampling permutation procedure, in which we\n",
    "shuffle together the results from groups A and B and then repeatedly deal out the\n",
    "data in groups of similar sizes, then observe how often we get a difference as\n",
    "extreme as the observed difference. See \"Resampling\" for more detail.\n",
    "\n",
    "### Alternative Hypothesis\n",
    "\n",
    "Hypothesis tests by their nature involve not just a null hypothesis, but also an\n",
    "offsetting alternative hypothesis. Here are some examples:\n",
    "- Null = \"no difference between the means of group A and group B,\" alternative = \"A is different from B\" (could be bigger or smaller)\n",
    "- Null = \"A <= B,\" alternative = \"B > A\"\n",
    "- Null = \"B is not X% greater than A,\" alternative = \"B is X% greater than A\"\n",
    "\n",
    "### One-Way, Two-Way Hypothesis Test\n",
    "\n",
    "Often, in an A/B test, you are testing a new option (say B), against an established\n",
    "default option (A) and the presumption is that you will stick with the default\n",
    "option unless the new option proves itself definitively better. In such a case, you\n",
    "want a hypothesis test to protect you from being fooled by chance in the\n",
    "direction favoring B. You don’t care about being fooled by chance in the other\n",
    "direction, because you would be sticking with A unless B proves definitively\n",
    "better. So you want a directional alternative hypothesis (B is better than A). In\n",
    "such a case, you use a _one-way_ (or one-tail) hypothesis test. This means that\n",
    "extreme chance results in only one direction direction count toward the p-value.\n",
    "\n",
    "If you want a hypothesis test to protect you from being fooled by chance in\n",
    "either direction, the alternative hypothesis is bidirectional (A is different from B;\n",
    "could be bigger or smaller). In such a case, you use a two-way (or two-tail)\n",
    "hypothesis. This means that extreme chance results in either direction count\n",
    "toward the p-value.\n",
    "\n",
    "A one-tail hypothesis test often fits the nature of A/B decision making, in which\n",
    "a decision is required and one option is typically assigned \"default\" status unless\n",
    "the other proves better. Software, however, including R, typically provides a\n",
    "two-tail test in its default output, and many statisticians opt for the more\n",
    "conservative two-tail test just to avoid argument. One-tail versus two-tail is a\n",
    "confusing subject, and not that relevant for data science, where the precision of\n",
    "p-value calculations is not terribly important.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- A null hypothesis is a logical construct embodying the notion that nothing special has happened, and any effect you observe is due to random chance.\n",
    "- The hypothesis test assumes that the null hypothesis is true, creates a \"null model\" (a probability model), and tests whether the effect you observe is a reasonable outcome of that model.\n",
    "\n",
    "## Resampling\n",
    "\n",
    "Resampling in statistics means to repeatedly sample values from observed data,\n",
    "with a general goal of assessing random variability in a statistic. It can also be\n",
    "used to assess and improve the accuracy of some machine-learning models (e.g. bagging in random forest models)\n",
    "\n",
    "There are two main types of resampling procedures: the bootstrap and\n",
    "permutation tests. The bootstrap is used to assess the reliability of an estimate; it\n",
    "was discussed in the previous chapter (see previously). Permutation tests\n",
    "are used to test hypotheses, typically involving two or more groups, and we\n",
    "discuss those in this section.\n",
    "\n",
    "- **Permutation test**: The procedure of combining two or more samples together, and randomly (or exhaustively) reallocating the observations to resamples.\n",
    "    - _Synonyms_: Randomization test, random permutation test, exact test.\n",
    "- **With or without replacement**: In sampling, whether or not an item is returned to the sample before the next draw.\n",
    " ### Permutation Test\n",
    " \n",
    "In a permutation procedure, two or more samples are involved, typically the\n",
    "groups in an A/B or other hypothesis test. Permute means to change the order of\n",
    "a set of values. The first step in a permutation test of a hypothesis is to combine\n",
    "the results from groups A and B (and, if used, C, D, ...) together. This is the\n",
    "logical embodiment of the null hypothesis that the treatments to which the\n",
    "groups were exposed do not differ. We then test that hypothesis by randomly\n",
    "drawing groups from this combined set, and seeing how much they differ from\n",
    "one another. The permutation procedure is as follows:\n",
    "\n",
    "1. Combine the results from the different groups in a single data set.\n",
    "2. Shuffle the combined data, then randomly draw (without replacing) a resample of the same size as group A.\n",
    "3. From the remaining data, randomly draw (without replacing) a resample of the same size as group B.\n",
    "4. Do the same for groups C, D, and so on.\n",
    "5. Whatever statistic or estimate was calculated for the original samples (e.g., difference in group proportions), calculate it now for the resamples, and record; this constitutes one permutation iteration.\n",
    "6. Repeat the previous steps R times to yield a permutation distribution of the test statistic.\n",
    "\n",
    "**Now go back to the observed difference between groups and compare it to the\n",
    "set of permuted differences. If the observed difference lies well within the set of\n",
    "permuted differences, then we have not proven anything—the observed\n",
    "difference is within the range of what chance might produce. However, if the\n",
    "observed difference lies outside most of the permutation distribution, then we\n",
    "conclude that chance is not responsible. In technical terms, the difference is\n",
    "statistically significant (p-values are further down)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
