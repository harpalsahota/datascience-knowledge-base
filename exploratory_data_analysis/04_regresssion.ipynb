{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import (\n",
    "    load_boston,\n",
    "    make_regression,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression models the relationship between the magnitude of one\n",
    "variable and that of a second—for example, as X increases, Y also increases. Or\n",
    "as X increases, Y decreases. Correlation is another way to measure how two\n",
    "variables are related. The difference is that while\n",
    "correlation measures the strength of an association between two variables,\n",
    "regression quantifies the nature of the relationship.\n",
    "\n",
    "### Key Terms\n",
    "\n",
    "- **Response**: The variable we are trying to predict.\n",
    "    - _Synonyms_: dependent variable, Y-variable, target, outcome\n",
    "- **Independent variable**: The variable used to predict the response.\n",
    "    - _Synonyms_: independent variable, X-variable, feature, attribute\n",
    "- **Record**: The vector of predictor and outcome values for a specific individual or case.\n",
    "    - _Synonyms_: row, case, instance, example\n",
    "- **Intercept**: The intercept of the regression line—that is, the predicted value when $X = 0$.\n",
    "    - _Synonyms_: $b_0, \\beta_0$\n",
    "- **Regression Coefficient**: The slop of the regression line.\n",
    "    - _Synonyms_: Slope, $b_1, \\beta_1$, parameter estimates, weights\n",
    "- **Fitted values**: The estimates obtained from the regression line.\n",
    "    - _Synonyms_: predicted values\n",
    "- **Residuals** The difference between the observed values and the fitted values.\n",
    "    - _Synonyms_: errors\n",
    "- **Least squares**: The method of fitting a regression by minimizing the sum of squared residuals.\n",
    "    - _Synonyms_: ordinary least squares\n",
    "    \n",
    "### Regression Equation\n",
    "\n",
    "Simple linear regression estimates exactly how much Y will change when X\n",
    "changes by a certain amount. With the correlation coefficient, the variables X\n",
    "and Y are interchangable. With regression, we are trying to predict the Y variable\n",
    "from X using a linear relationship (i.e., a line):\n",
    "\n",
    "\\begin{equation}\n",
    "Y = b_0 + b_1X\n",
    "\\end{equation}\n",
    "\n",
    "We read this as \"Y equals $b_1$ times X, plus a constant $b_0$ .” The symbol $b_0$ is\n",
    "known as the intercept (or constant), and the symbol $b_1$ as the slope for X. Both\n",
    "can be called coefficients, though in general use the term coefficient is\n",
    "often reserved for $b_1$. The Y variable is known as the response or dependent\n",
    "variable since it depends on X. The X variable is known as the predictor or\n",
    "independent variable. The machine learning community tends to use other terms,\n",
    "calling Y the target and X a feature vector.\n",
    "\n",
    "Let's look at a synthetic example below. A dataset has been created with 100\n",
    "data points, 1 feature, 1 feature being informative and one target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_regression(\n",
    "    n_samples=100,\n",
    "    n_features=1,\n",
    "    n_informative=1,\n",
    "    n_targets=1,\n",
    "    noise=10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f8d6490648>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the plot the X is clearly correlated with Y.\n",
    "But how is Y related to X?\n",
    "\n",
    "Simple linear regression tries to find the \"best\" line to predict the response Y\n",
    "as a function of the predictor variable X.\n",
    "\n",
    "\\begin{equation}\n",
    "Y = b_0 + b_1X\n",
    "\\end{equation}\n",
    "\n",
    "We can quatify the relation ship by fitting a linear model to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([44.43716999]), 1.1651153205269726)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression().fit(x, y)\n",
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept or $b_0$ is 0.144 and can be interpreted as the predicted Y for when X is zero.\n",
    "The regression coefficient or $b_1$ can be interpreted as follows: for each additional unit of X\n",
    "the value of Y increases by 54.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-87.71499999999999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. X = -2\n",
    "1.165 + 44.44 * -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.165"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. X = 0\n",
    "1.165 + 44.44 * 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression line from this model is displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8d9583808>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, lr.predict(x), color='blue', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slope or $b_1$ can be calculated as: $b_1 = \\Delta Y / \\Delta X $ \n",
    "\n",
    "### Fitted Values and Residuals\n",
    "\n",
    "Generally, data doesn't fit on a straight line so the regression line should include\n",
    "an error term $e_i$:\n",
    "\n",
    "\\begin{equation}\n",
    "Y_i = b_0 + b_1X_i + e_i\n",
    "\\end{equation}\n",
    "\n",
    "Fitted values are referred to as predicted values and are typically denoted by $\\hat{Y}_i$ (Y-hat). \n",
    "The fitted values are given by:\n",
    "\\begin{equation}\n",
    "\\hat{Y}_i = \\hat{b}_0 + \\hat{b_1}X_i\n",
    "\\end{equation}\n",
    "\n",
    "The $\\hat{}$ notation of the co-efficients indicates these are estimated and not known.\n",
    "\n",
    "The residuals $\\hat{e}_i$ is computed by subtracting the predicted values from the original data:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{e}_i = Y_i - \\hat{Y}_i\n",
    "\\end{equation}\n",
    "\n",
    "The residuals are the length of the vertical dashed lines from the data line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1f8de415088>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = y - lr.predict(x)\n",
    "\n",
    "segments = [[[x[i], y[i]], [x[i], y[i] - residuals[i]]] for i in range(y.shape[0])]\n",
    "lc = LineCollection(segments, zorder=0, linewidths=5.0, linestyle='--', colors='red')\n",
    "lc.set_array(np.ones(len(y)))\n",
    "lc.set_linewidths(np.full(y.shape[0], 0.5))\n",
    "\n",
    "fig, (ax0) = plt.subplots(ncols=1, figsize=(12, 6))\n",
    "\n",
    "ax0.plot(x, y, 'C0.', markersize=12)\n",
    "ax0.plot(x, lr.predict(x), 'C2-')\n",
    "ax0.add_collection(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares\n",
    "\n",
    "How is the model fit to the data? When there is a clear relationship, you could\n",
    "imagine fitting the line by hand. In practice, the regression line is the estimate\n",
    "that minimizes the sum of squared residual values, also called the _residual sum\n",
    "of squares_ or RSS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "RSS = \\sum^n_{i=1}(Y_{i}-\\hat{Y}_i)^2 \\\\\n",
    "= \\sum^n_{i=1}(Y_i-\\hat{b}_0-\\hat{b}_1X_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "The estimates $\\hat{b}_0$ and $\\hat{b}_1$ are the values that minimize RSS.\n",
    "\n",
    "The method of minimizing the sum of the squared residuals is termed least\n",
    "squares regression, or ordinary least squares (OLS) regression. Least\n",
    "squares regression leads to a simple formula to compute the coefficients:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{b}_1 = \\frac{\\sum^n_{i=1}(Y_{i}-\\overline{Y}_i)(X_i-\\overline{X})}{\\sum^n_{i=1}(X_i-\\overline{X})^2} \\\\\n",
    "\\hat{b}_0 = \\overline{Y} - \\hat{b}_1\\overline{X}\n",
    "\\end{equation}\n",
    "\n",
    "Least squares, like the mean, are sensitive to outliers, although this tends to be a signicant\n",
    "problem only in small or moderate-sized problems\n",
    "\n",
    "### Prediction versus Explanation (Profiling)\n",
    "\n",
    "With the advent of big data, regression is widely used to form a model to predict\n",
    "individual outcomes for new data, rather than explain data in hand (i.e., a\n",
    "predictive model). In this instance, the main items of interest are the fitted values\n",
    "$\\hat{Y}$. In marketing, regression can be used to predict the change in revenue in\n",
    "response to the size of an ad campaign.\n",
    "\n",
    "A regression model that fits the data well is set up such that changes in X lead to\n",
    "changes in Y. However, by itself, the regression equation does not prove the\n",
    "direction of causation. Conclusions about causation must come from a broader\n",
    "context of understanding about the relationship. For example, a regression\n",
    "equation might show a definite relationship between number of clicks on a web\n",
    "ad and number of conversions. It is our knowledge of the marketing process, not\n",
    "the regression equation, that leads us to the conclusion that clicks on the ad lead\n",
    "to sales, and not vice versa.\n",
    "\n",
    "### Key Takeaways\n",
    "- The regression equation models the relationship between a response variable Y and a predictor variable X as a line.\n",
    "- A regression model yields fitted values and residuals—predictions of the response and the errors of the predictions.\n",
    "- Regression models are typically fit by the method of least squares.\n",
    "- Regression is used both for prediction and explanation.\n",
    "\n",
    "## Multiple Linear Regression\n",
    "\n",
    "When there are multiple predictors, the equation is simply extended to\n",
    "accommodate them:\n",
    "\n",
    "\\begin{equation}\n",
    "Y = b_0 + b_1X_1 + b_2X_2 + ... + b_pX_p + e\n",
    "\\end{equation}\n",
    "\n",
    "- **Root mean squared error**: The square root of the average squared error of the regression (this is the most widely used metric to compare regression models).\n",
    "    - _Synonyms_: RMSE\n",
    "- **Residual standard error**:\n",
    "The same as the root mean squared error, but adjusted for degrees of\n",
    "freedom.\n",
    "Synonyms\n",
    "RSE\n",
    "- **R-squared**: The proportion of variance explained by the model, from 0 to 1.\n",
    "    - _Synonyms_:coefficient of determination, $R^2$\n",
    "- **t-statistic**: The coefficient for a predictor, divided by the standard error of the coefficient, giving a metric to compare the importance of variables in the model.\n",
    "- **Weighted regression**: Regression with the records having different weights.\n",
    "\n",
    "All of the other concepts in simple linear regression, such as fitting by least\n",
    "squares and the definition of fitted values and residuals, extend to the multiple\n",
    "linear regression setting. For example, the fitted values are given by:\n",
    "\\begin{equation}\n",
    "\\hat{Y} = \\hat{b_0} + \\hat{b_1}X_{1,i} + \\hat{b_2}X_{2,i} + ... + \\hat{b_p}X_{p,i} + e\n",
    "\\end{equation}\n",
    "\n",
    "The interpretation of the coefficients is as with simple linear regression: the\n",
    "predicted value $\\hat{Y}$ changes by the coefficient $b_j$ for each unit change in $X_j$\n",
    "assuming all the other variables, for $k \\neq j$, remain the same.\n",
    "\n",
    "### Addessing the Model\n",
    "\n",
    "The most important performance metric from a data science perspective is root\n",
    "mean squared error, or RMSE. RMSE is the square root of the average squared\n",
    "error in the predicted $\\hat{y}_i$ values:\n",
    "\\begin{equation}\n",
    "RMSE = \\sqrt{\\frac{\\sum^n_{i=1}{(y_i-\\hat{y_i})^2}}{n}}\n",
    "\\end{equation}\n",
    "This measures the overall accuracy of the model, and is a basis for comparing it\n",
    "to other models (including models fit using machine learning techniques).\n",
    "Similar to RMSE is the residual standard error, or RSE. In this case we have $p$\n",
    "predictors, and the RSE is given by:\n",
    "\\begin{equation}\n",
    "RSE = \\sqrt{\\frac{\\sum^n_{i=1}{(y_i-\\hat{y_i})^2}}{n-p-1}}\n",
    "\\end{equation}\n",
    "The only difference is that the denominator is the degrees of freedom, as\n",
    "opposed to number of records. In practice, for linear\n",
    "regression, the difference between RMSE and RSE is very small, particularly for\n",
    "big data applications.\n",
    "Another useful metric that you will see in software output is the coefficient of\n",
    "determination, also called the R-squared statistic or $R^2$. R-squared ranges from\n",
    "0 to 1 and measures the proportion of variation in the data that is accounted for\n",
    "in the model. It is useful mainly in explanatory uses of regression where you\n",
    "want to assess how well the model fits the data. The formula for $R^2$ is:\n",
    "\\begin{equation}\n",
    "R^2 = 1 - \\frac{\\sum^n_{i=1}{(y_i-\\hat{y_i})^2}}{\\sum^n_{i=1}{(y_i-\\overline{y_i})^2}}\n",
    "\\end{equation}\n",
    "The denominator is proportional to the variance of Y. You may also see reported the\n",
    "adjusted R-squared, which adjusts for the degrees of freedom; seldom\n",
    "is this significantly different in multiple regression.\n",
    "\n",
    "### Model Selection and Stepwise Regression\n",
    "\n",
    "In some problems, many variables could be used as predictors in a regression.\n",
    "For example, to predict house value, additional variables such as the basement\n",
    "size or year built could be used.\n",
    "\n",
    "Adding more variables, however, does not necessarily mean we have a better\n",
    "model. Statisticians use the principle of Occam’s razor to guide the choice of a\n",
    "model: all things being equal, a simpler model should be used in preference to a\n",
    "more complicated model.\n",
    "\n",
    "Including additional variables always reduces RMSE and increases $R^2$. Hence,\n",
    "these are not appropriate to help guide the model choice. In the 1970s, Hirotugu\n",
    "Akaike, the eminent Japanese statistician, deveoped a metric called AIC\n",
    "(Akaike’s Information Criteria) that penalizes adding terms to a model. In the\n",
    "case of regression, AIC has the form:\n",
    "\n",
    "\\begin{equation}\n",
    "AIC = 2P + n log(RSS/n)\n",
    "\\end{equation}\n",
    "\n",
    "where p is the number of variables and n is the number of records. The goal is to\n",
    "find the model that minimizes AIC; models with k more extra variables are\n",
    "penalized by 2k. RSS is the residual sum of squares.\n",
    "\n",
    "How do we find the model that minimizes AIC? One approach is to search\n",
    "through all possible models, called all subset regression. This is computationally\n",
    "expensive and is not feasible for problems with large data and many variables.\n",
    "An attractive alternative is to use stepwise regression, which successively adds\n",
    "and drops predictors to find a model that lowers AIC.\n",
    "\n",
    "Is is possible to try forward selection and backward selection. In forward selection,\n",
    "you start with no predictors and add them one-by-one, at each step adding the\n",
    "predictor that has the largest contribution to , stopping when the contribution\n",
    "is no longer statistically significant. In backward selection, or backward\n",
    "elimination, you start with the full model and take away predictors that are not\n",
    "statistically significant until you are left with a model in which all predictors are\n",
    "statistically significant.\n",
    "\n",
    "Penalized regression is similar in spirit to AIC. Instead of explicitly searching\n",
    "through a discrete set of models, the model-fitting equation incorporates a\n",
    "constraint that penalizes the model for too many variables (parameters). Rather\n",
    "than eliminating predictor variables entirely—as with stepwise, forward, and\n",
    "backward selection—penalized regression applies the penalty by reducing\n",
    "coefficients, in some cases to near zero. Common penalized regression methods\n",
    "are _ridge regression_ and _lasso regression_.\n",
    "\n",
    "Stepwise regression and all subset regression are in-sample methods to assess\n",
    "and tune models. This means the model selection is possibly subject to\n",
    "overfitting and may not perform as well when applied to new data. One common\n",
    "approach to avoid this is to use cross-validation to validate the models. In linear\n",
    "regression, overfitting is typically not a major issue, due to the simple (linear)\n",
    "global structure imposed on the data. For more sophisticated types of models,\n",
    "particularly iterative procedures that respond to local data structure, crossvalidation\n",
    "is a very important tool.\n",
    "\n",
    "### Weighted Regression\n",
    "\n",
    "Weighted regression is used by statisticians for a variety of purposes; in\n",
    "particular, it is important for analysis of complex surveys. Data scientists may\n",
    "find weighted regression useful in two cases:\n",
    "\n",
    "- Inverse-variance weighting when different observations have been measured with different precision.\n",
    "- Analysis of data in an aggregated form such that the weight variable encodes how many original observations each row in the aggregated data represents.\n",
    "\n",
    "The coefficents in the weighted regression are slightly different from the original\n",
    "regression.\n",
    "\n",
    "### Key Takeaways\n",
    "- Multiple linear regression models the relationship between a response variable Y and multiple predictor variables $X_1, ..., X_p$\n",
    "- The most important metrics to evaluate a model are root mean squared error (RMSE) and R-squared ($R^2$).\n",
    "- The standard error of the coefficients can be used to measure the reliability of a variable’s contribution to a model.\n",
    "- Stepwise regression is a way to automatically determine which variables should be included in the model.\n",
    "- Weighted regression is used to give certain records more or less weight in fitting the equation.\n",
    "\n",
    "## Prediction Using Regression\n",
    "\n",
    "- **Prediction interval**: An uncertainty interval around an individual predicted value.\n",
    "- **Extrapolation**: Extension of a model beyond the range of the data used to fit it.\n",
    "\n",
    "Regression models should not be used to extrapolate beyond the range of the\n",
    "data. The model is valid only for predictor values for which the data has\n",
    "sufficient values (even in the case that sufficient data is available, there could be\n",
    "other problems)\n",
    "\n",
    "### Confidence and Prediction Intervals\n",
    "\n",
    "Much of statistics involves understanding and measuring variability\n",
    "(uncertainty). Confidence intervals which are\n",
    "uncertainty intervals placed around regression coefficients and predictions. An\n",
    "easy way to understand this is via the bootstrap (see “The Bootstrap” for more\n",
    "details about the general bootstrap procedure). The most common regression\n",
    "confidence intervals encountered in software output are those for regression\n",
    "parameters (coefficients). Here is a bootstrap algorithm for generating\n",
    "confidence intervals for regression parameters (coefficients) for a data set with P\n",
    "predictors and n records (rows):\n",
    "\n",
    "1. Consider each row (including outcome variable) as a single \"ticket\" and place all the n tickets in a box.\n",
    "2. Draw a ticket at random, record the values, and replace it in the box.\n",
    "3. Repeat step 2 n times; you now have one bootstrap resample.\n",
    "4. Fit a regression to the bootstrap sample, and record the estimated coefficients.\n",
    "5. Repeat steps 2 through 4, say, 1,000 times.\n",
    "6. You now have 1,000 bootstrap values for each coefficient; find the appropriate percentiles for each one (e.g., 5th and 95th for a 90% confidence interval).\n",
    "\n",
    "The conceptual meaning and interpretation are the\n",
    "same, and not of central importance to data scientists, because they concern the\n",
    "regression coefficients. Of greater interest to data scientists are intervals around\n",
    "predicted y values ($\\hat{Y}_i$). The uncertainty \\hat{Y}_i around comes from two sources:\n",
    "\n",
    "- Uncertainty about what the relevant predictor variables and their coefficients are (see the preceding bootstrap algorithm)\n",
    "- Additional error inherent in individual data points\n",
    "\n",
    "The individual data point error can be thought of as follows: even if we knew for\n",
    "certain what the regression equation was (e.g., if we had a huge number of\n",
    "records to fit it), the actual outcome values for a given set of predictor values\n",
    "will vary. The bootstrap algorithm for modeling both the regression model error and the individual data\n",
    "point error would look as follows:\n",
    "\n",
    "1. Take a bootstrap sample from the data (spelled out in greater detail earlier).\n",
    "2. Fit the regression, and predict the new value.\n",
    "3. Take a single residual at random from the original regression fit, add it to the predicted value, and record the result.\n",
    "4. Repeat steps 1 through 3, say, 1,000 times.\n",
    "5. Find the 2.5th and the 97.5th percentiles of the results.\n",
    "\n",
    "**PREDICTION INTERVAL OR CONFIDENCE INTERVAL?**\n",
    "_A prediction interval pertains to uncertainty around a single value, while a confidence interval\n",
    "pertains to a mean or other statistic calculated from multiple values. Thus, a prediction interval\n",
    "will typically be much wider than a confidence interval for the same value. We model this\n",
    "individual value error in the bootstrap model by selecting an individual residual to tack on to\n",
    "the predicted value. Which should you use? That depends on the context and the purpose of the\n",
    "analysis, but, in general, data scientists are interested in specific individual predictions, so a\n",
    "prediction interval would be more appropriate. Using a confidence interval when you should\n",
    "be using a prediction interval will greatly underestimate the uncertainty in a given predicted\n",
    "value._\n",
    "\n",
    "### Key Takeaways\n",
    "- Extrapolation beyond the range of the data can lead to error.\n",
    "- Confidence intervals quantify uncertainty around regression coefficients.\n",
    "- Prediction intervals quantify uncertainty in individual predictions.\n",
    "- Most software, R included, will produce prediction and confidence intervals in default or specified output, using formulas.\n",
    "- The bootstrap can also be used; the interpretation and idea are the same.\n",
    "\n",
    "## Categorical Variables in Regression\n",
    "\n",
    "Regression requires numerical inputs, so categorical variables need to be recoded to use in the model. The\n",
    "most common approach is to convert a variable into a set of binary dummy variables.\n",
    "\n",
    "- **Dummy variables**: Binary 0–1 variables derived by recoding factor data for use in regression and other models.\n",
    "- **Reference coding**: The most common type of coding used by statisticians, in which one level of a factor is used as a reference and other factors are compared to that level.\n",
    "    - _Synonyms_: treatment coding\n",
    "- **One hot encoder**: A common type of coding used in the machine learning community in which all categorical levels are retained. While useful for certain machine learning algorithms, this approach is not appropriate for multiple linear regression.\n",
    "- **Deviation coding**: A type of coding that compares each level against the overall mean as opposed to the reference level.\n",
    "    - _Synonyms_: sum contrasts\n",
    "    \n",
    "Imagine we have a categorical feature that can take on three values: `Multiplex`, `Single Family` or `Townhouse`. To use this categorical variable, \n",
    "we need to convert it to a set of binary variables. We do this by creating a binary variable for each possible value of the categorical\n",
    "variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muliplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Townhouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Property Type\n",
       "0       Muliplex\n",
       "1  Single Family\n",
       "2  Single Family\n",
       "3      Townhouse"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Property Type': ['Muliplex', 'Single Family', 'Single Family', 'Townhouse']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert them to binary variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property Type_Muliplex</th>\n",
       "      <th>Property Type_Single Family</th>\n",
       "      <th>Property Type_Townhouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Property Type_Muliplex  Property Type_Single Family  \\\n",
       "0                       1                            0   \n",
       "1                       0                            1   \n",
       "2                       0                            1   \n",
       "3                       0                            0   \n",
       "\n",
       "   Property Type_Townhouse  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factor categorical PropertyType, which has three distinct levels,\n",
    "is represented as a matrix with three columns. In the machine learning\n",
    "community, this representation is referred to as one hot encoding.\n",
    "In certain machine learning algorithms, such as nearest neighbors and\n",
    "tree models, one hot encoding is the standard way to represent categorical variables\n",
    "\n",
    "**DIFFERENT FACTOR CODINGS**\n",
    "_There are several different ways to encode factor variables, known as contrast coding systems.\n",
    "For example, deviation coding, also know as sum contrasts, compares each level against the\n",
    "overall mean. Another contrast is polynomial coding, which is appropriate for ordered factors;\n",
    "see the section \"Ordered Factor Variables\". With the exception of ordered factors, data\n",
    "scientists will generally not encounter any type of coding besides reference coding or one hot\n",
    "encoder._\n",
    "\n",
    "## Categorical Variables with Many Levels\n",
    "\n",
    "Some categorical variables can produce a huge number of binary dummies e.g postal codes. In such\n",
    "cases, it is useful to explore the data, and the relationships between predictor\n",
    "variables and the outcome, to determine whether useful information is contained\n",
    "in the categories. If so, you must further decide whether it is useful to retain all\n",
    "factors, or whether the levels should be consolidated.\n",
    "\n",
    "One approach is to group the postal codes according to another variable,\n",
    "such as sale price. Even better is to form postal code groups using the residuals\n",
    "from an initial model. For example, the median residual is computed for each postal code and the ntile function is used to\n",
    "split the postal codes, sorted by the median, into five groups\n",
    "\n",
    "### Ordered Factor Variables\n",
    "\n",
    "Some categorical variables reflect levels of a category; these are termed ordered factor\n",
    "variables or ordered categorical variables. For example, the loan grade could be\n",
    "A, B, C, and so on—each grade carries more risk than the prior grade. Ordered\n",
    "categorical variables can typically be converted to numerical values and used as is. \n",
    "Treating ordered categorical variables as a numeric variable preserves the information\n",
    "contained in the ordering that would be lost if it were converted to a factor.\n",
    "\n",
    "### Key Takeaways\n",
    "- Factor variables need to be converted into numeric variables for use in a regression.\n",
    "- The most common method to encode a factor variable with P distinct values is to represent them using P-1 dummy variables.\n",
    "- A factor variable with many levels, even in very big data sets, may need to be consolidated into a variable with fewer levels.\n",
    "- Some factors have levels that are ordered and can be represented as a single numeric variable.\n",
    "\n",
    "## Interpreting the Regression Equation\n",
    "\n",
    "In data science, the most important use of regression is to predict some\n",
    "dependent (outcome) variable. In some cases, however, gaining insight from the\n",
    "equation itself to understand the nature of the relationship between the predictors\n",
    "and the outcome can be of value.\n",
    "\n",
    "- **Correlated variables**: When the predictor variables are highly correlated, it is difficult to interpret the individual coefficients.\n",
    "- **Multicollinearity**: When the predictor variables have perfect, or near-perfect, correlation, the regression can be unstable or impossible to compute.\n",
    "    - _Synonyms_: collinearity\n",
    "- **Confounding variables** An important predictor that, when omitted, leads to spurious relationships in a regression equation.\n",
    "- **Main effects**: The relationship between a predictor and the outcome variable, independent from other variables.\n",
    "- **Interactions** An interdependent relationship between two or more predictors and the response.\n",
    "\n",
    "### Correlated Predictors\n",
    "\n",
    "In multiple regression, the predictor variables are often correlated with each\n",
    "other. For example if looking at housing data the coefficient for Bedrooms\n",
    "maybe negative, this implies that adding bedrooms to a house will reduce its value. This is because the predictor\n",
    "variables are correlated: larger houses tend to have more bedrooms, and it is the\n",
    "size that drives house value, not the number of bedrooms. Consider two homes\n",
    "of the exact same size: it is reasonable to expect that a home with more, but\n",
    "smaller, bedrooms would be considered less desirable.\n",
    "\n",
    "Having correlated predictors can make it difficult to interpret the sign and value\n",
    "of regression coefficients (and can inflate the standard error of the estimates).\n",
    "The variables for bedrooms, house size, and number of bathrooms are all\n",
    "correlated.\n",
    "\n",
    "Correlated variables are only one issue with interpreting regression coefficients.\n",
    "\n",
    "### Multicollinearity\n",
    "\n",
    "An extreme case of correlated variables produces multicollinearity—a condition\n",
    "in which there is redundance among the predictor variables. Perfect\n",
    "multicollinearity occurs when one predictor variable can be expressed as a linear\n",
    "combination of others. Multicollinearity occurs when:\n",
    "\n",
    "- A variable is included multiple times by error.\n",
    "- P dummies, instead of P – 1 dummies, are created from a factor variable.\n",
    "- Two variables are nearly perfectly correlated with one another.\n",
    "\n",
    "**Multicollinearity in regression must be addressed—variables should be removed\n",
    "until the multicollinearity is gone.** A regression does not have a well-defined\n",
    "solution in the presence of perfect multicollinearity\n",
    "\n",
    "### Confounding Variables\n",
    "With correlated variables, the problem is one of **commission**: including different\n",
    "variables that have a similar predictive relationship with the response. With\n",
    "confounding variables, the problem is one of **omission**: an important variable is\n",
    "not included in the regression equation. Naive interpretation of the equation\n",
    "coefficients can lead to invalid conclusions.\n",
    "\n",
    "For example a housing dataset without postal code does not contain information on location - \n",
    "a very important predictor in house price!\n",
    "\n",
    "### Interactions and Main Effects\n",
    "\n",
    "Statisticians like to distinguish between main effects, or independent variables,\n",
    "and the interactions between the main effects. Main effects are what are often\n",
    "referred to as the predictor variables in the regression equation. An implicit\n",
    "assumption when only main effects are used in a model is that the relationship\n",
    "between a predictor variable and the response is independent of the other\n",
    "predictor variables. This is often not the case.\n",
    "\n",
    "For example, location in real estate is everything, and it is natural to presume that the\n",
    "relationship between, say, house size and the sale price depends on location. A\n",
    "big house built in a low-rent district is not going to retain the same value as a big\n",
    "house built in an expensive area.\n",
    "\n",
    "#### Model Selection with Interaction Terms\n",
    "\n",
    "In problems involving many variables, it can be challenging to decide which interaction terms\n",
    "should be included in the model. Several different approaches are commonly taken:\n",
    "\n",
    "- In some problems, prior knowledge and intuition can guide the choice of which interaction terms to include in the model.\n",
    "- Stepwise selection (see \"Model Selection and Stepwise Regression\") can be used to sift through the various models.\n",
    "- Penalized regression can automatically fit to a large set of possible interaction terms.\n",
    "- Perhaps the most common approach is the use tree models, as well as their descendents, random forest and gradient boosted trees. This class of models automatically searches for optimal interaction terms\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Because of correlation between predictors, care must be taken in the interpretation of the coefficients in multiple linear regression.\n",
    "- Multicollinearity can cause numerical instability in fitting the regression equation.\n",
    "- A confounding variable is an important predictor that is omitted from a model and can lead to a regression equation with spurious relationships.\n",
    "- An interaction term between two variables is needed if the relationship between the variables and the response is interdependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
